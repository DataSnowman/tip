{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS tipspark\")\n",
        "spark.sql(\"CREATE TABLE IF NOT EXISTS tipspark.date_dim USING DELTA LOCATION 'abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphack/date_dim/AutoLoader/data/'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "dfdim = spark.sql(\"SELECT * from tipspark.date_dim\")\n",
        "display(dfdim.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "dfsales = spark.sql(\"SELECT * from tipspark.catalog_sales\")\n",
        "display(dfsales.limit(10))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "df = spark.sql(\"SELECT * from tipspark.catalog_sales, tipspark.date_dim WHERE tipspark.catalog_sales.cs_sold_date_sk = tipspark.date_dim.d_date_sk\")\n",
        "display(df.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "cols = (\"d_date_sk\",\"d_date_id\",\"d_month_seq\",\"d_week_seq\",\"d_quarter_seq\",\"d_year\",\"d_dow\",\"d_moy\",\"d_dom\",\"d_qoy\",\"d_fy_year\",\"d_fy_quarter_seq\",\"d_fy_week_seq\",\"d_day_name\",\"d_quarter_name\",\"d_holiday\",\"d_weekend\",\"d_following_holiday\",\"d_first_dom\",\"d_last_dom\",\"d_same_day_ly\",\"d_same_day_lq\",\"d_current_day\",\"d_current_week\",\"d_current_month\",\"d_current_quarter\",\"d_current_year\")\n",
        "          \n",
        "df2 = df.drop(*cols)\n",
        "df2.printSchema()\n",
        "display(df2.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql.functions import split\n",
        "\n",
        "# split() function defining parameters\n",
        "split_cols = split(df2['d_date'], '-')\n",
        "  \n",
        "# Now applying split() using withColumn()\n",
        "dfsplit = df2.withColumn('year', split_cols.getItem(0)) \\\n",
        "    .withColumn('month', split_cols.getItem(1)) \\\n",
        "    .withColumn('day', split_cols.getItem(2))\n",
        "    \n",
        "  \n",
        "# display df\n",
        "display(dfsplit.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import to_date, concat, lit, col\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "dffinal1 = dfsplit.withColumn('d_date_new',to_date(dfsplit.d_date, 'yyyy-MM-dd'))\n",
        "dffinal2 = dffinal1.select(\"*\", concat(col(\"year\"),col(\"month\"),col(\"day\")).alias(\"date_integer\"))\n",
        "dffinal2 = dffinal2.withColumn(\"date_integer\",dffinal2[\"date_integer\"].cast(IntegerType()))\n",
        "dffinal2.printSchema()\n",
        "display(dffinal2.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Parquet\n",
        "dffinal2.write.format('parquet')\\\n",
        "  .mode('overwrite')\\\n",
        "  .partitionBy (\"year\", \"month\", \"day\")\\\n",
        "  .save('abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackparquet/catalog_sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "dfparq = spark.read.load('abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackparquet/catalog_sales', format='parquet')\n",
        "dfparq.printSchema()\n",
        "display(dfparq.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#  Delta\n",
        "dffinal2.write.format('delta')\\\n",
        "  .mode('overwrite')\\\n",
        "  .option(\"overwriteSchema\", \"true\")\\\n",
        "  .partitionBy (\"year\", \"month\", \"day\")\\\n",
        "  .save('abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackdelta/catalog_sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "metadata": {
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS tipspark\")\n",
        "spark.sql(\"CREATE TABLE IF NOT EXISTS tipspark.catalog_sales_parquet USING PARQUET LOCATION 'abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackparquet/catalog_sales/*/*/*/*.snappy.parquet'\")\n",
        "dfdisp = spark.sql(\"select * from tipspark.catalog_sales_parquet\")\n",
        "\n",
        "display(dfdisp.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS tipspark\")\n",
        "spark.sql(\"CREATE TABLE IF NOT EXISTS tipspark.catalog_sales_delta USING DELTA LOCATION 'abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackdelta/catalog_sales/'\")\n",
        "dfdisp = spark.sql(\"select * from tipspark.catalog_sales_delta\")\n",
        "\n",
        "display(dfdisp.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\n",
        "\n",
        "select count(*) from tipspark.catalog_sales_delta where year = 2001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\n",
        "dfdelta = spark.read.load('abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackdelta/catalog_sales', format='delta')\n",
        "display(dfdelta.limit(10))\n",
        "dfdelta.printSchema()"
      ]
    }
  ]
}