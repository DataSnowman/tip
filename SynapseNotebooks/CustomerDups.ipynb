{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      },
      "source": [
        "%%pyspark\r\n",
        "dfdelta = spark.read.load('abfss://commonzone@synapsetiphackathon.dfs.core.windows.net/enricheddata/tiphackdelta/customer', format='delta')\r\n",
        "display(dfdelta.limit(10))\r\n",
        "dfdelta.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfcust = dfdelta.dropDuplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# extracting number of distinct rows\r\n",
        "  # from the Dataframe\r\n",
        "\r\n",
        "numrows = dfcust.distinct().count()\r\n",
        "\r\n",
        "   \r\n",
        "# extracting total number of rows from\r\n",
        "# the Dataframe\r\n",
        "all_rows = dfcust.count()\r\n",
        "   \r\n",
        "# extracting number of columns from the\r\n",
        "# Dataframe\r\n",
        "col = len(dfcust.columns)\r\n",
        " \r\n",
        "# printing\r\n",
        "print(f'Distinct Number of Rows are: {numrows}')\r\n",
        "print(f'Total Number of Rows are: {all_rows}')\r\n",
        "print(f'Number of Columns are: {col}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\r\n",
        "from pyspark.sql import Row\r\n",
        "listOfColumns = (\"c_customer_sk\",\"c_customer_id\",\"c_current_addr_sk\")\r\n",
        "if dfdelta.count() > dfdelta.dropDuplicates([listOfColumns]).count():\r\n",
        "    raise ValueError('Data has duplicates')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "dfdelta.exceptAll(dfdelta.dropDuplicates([\"c_customer_sk\"]))\r\n",
        "display(dfdelta.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# extracting number of distinct rows\r\n",
        "  # from the Dataframe\r\n",
        "\r\n",
        "numrows = dfdelta.distinct().count()\r\n",
        "\r\n",
        "   \r\n",
        "# extracting total number of rows from\r\n",
        "# the Dataframe\r\n",
        "all_rows = dfdelta.count()\r\n",
        "   \r\n",
        "# extracting number of columns from the\r\n",
        "# Dataframe\r\n",
        "col = len(dfdelta.columns)\r\n",
        " \r\n",
        "# printing\r\n",
        "print(f'Distinct Number of Rows are: {numrows}')\r\n",
        "print(f'Total Number of Rows are: {all_rows}')\r\n",
        "print(f'Number of Columns are: {col}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "import pyspark.sql.functions as f\r\n",
        "\r\n",
        "dfdelta.join(\r\n",
        "dfdelta.groupBy(dfdelta.columns).agg((f.count(\"*\")>1).cast(\"int\").alias(\"Duplicate_indicator\")),\r\n",
        "on=dfdelta.columns,\r\n",
        "how=\"inner\"\r\n",
        ").show()\r\n",
        "display(dfdelta.limit(10))\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# extracting number of distinct rows\r\n",
        "  # from the Dataframe\r\n",
        "\r\n",
        "numrows = dfdelta.distinct().count()\r\n",
        "\r\n",
        "   \r\n",
        "# extracting total number of rows from\r\n",
        "# the Dataframe\r\n",
        "all_rows = dfdelta.count()\r\n",
        "   \r\n",
        "# extracting number of columns from the\r\n",
        "# Dataframe\r\n",
        "col = len(dfdelta.columns)\r\n",
        " \r\n",
        "# printing\r\n",
        "print(f'Distinct Number of Rows are: {numrows}')\r\n",
        "print(f'Total Number of Rows are: {all_rows}')\r\n",
        "print(f'Number of Columns are: {col}')"
      ]
    }
  ]
}