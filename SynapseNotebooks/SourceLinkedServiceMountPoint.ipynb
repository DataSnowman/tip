{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Mount to Blob Storage Source**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "outputs": [],
      "metadata": {},
      "source": [
        "from notebookutils import mssparkutils\n",
        "\n",
        "# Azure storage access info\n",
        "source_blob_account_name = 'datasnowman' # replace with your blob name\n",
        "source_blob_container_name = 'tiphackathon' # replace with your container name\n",
        "source_blob_relative_path = 'catalog_sales' # replace with your relative folder path\n",
        "source_linked_service_name = 'AzureBlobStorageTIP' # replace with your linked service name\n",
        "\n",
        "source_blob_sas_token = mssparkutils.credentials.getConnectionStringOrCreds(source_linked_service_name)\n",
        "#spark.conf.set('fs.azure.sas.{source_blob_container_name}.{source_blob_account_name}.blob.core.windows.net', blob_sas_token)\n",
        "#print(source_blob_sas_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Allow SPARK to access from Blob remotely\n",
        "source_wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (source_blob_container_name, source_blob_account_name, source_blob_relative_path)\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (source_blob_container_name, source_blob_account_name), source_blob_sas_token)\n",
        "print('Remote blob path: ' + source_wasbs_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "mssparkutils.fs.unmount(\"/mnt/blobsource\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "mssparkutils.fs.mount( \n",
        "    #\"wasbs://tiphackathon@datasnowman.blob.core.windows.net/catalog_sales/\",\n",
        "    f\"{source_wasbs_path}\", \n",
        "    \"/mnt/blobsource\",\n",
        "    {\"linkedService\":f\"{source_linked_service_name}\"} \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "files = mssparkutils.fs.ls(\"/\")\r\n",
        "for file in files:\r\n",
        "    print(file.name, file.isDir, file.isFile, file.path, file.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#jobId = mssparkutils.env.getJobId() \r\n",
        "#f = open(f\"/synfs/{jobId}/mnt/blobsource/myFile.txt\", \"a\") \r\n",
        "#f.write(\"Hello world.\") \r\n",
        "#f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "jobId = mssparkutils.env.getJobId()\r\n",
        "#print(jobId)\r\n",
        "source_files = mssparkutils.fs.ls(f\"synfs:/{jobId}/mnt/blobsource/catalog_sales/\")\r\n",
        "for file in source_files:\r\n",
        "    print(file.name, file.isDir, file.isFile, file.path, file.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Mount ADLS Storage Sink**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from notebookutils import mssparkutils\n",
        "\n",
        "# Primary storage info\n",
        "sink_account_name = 'synapsetiphackathon' # fill in your primary account name\n",
        "sink_container_name = 'landingzone' # fill in your container name\n",
        "sink_relative_path = 'raw' # fill in your relative folder path\n",
        "sink_linked_service_name = 'AzureDataLakeStorageTIP' # replace with your linked service name\n",
        "\n",
        "sink_adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (sink_container_name, sink_account_name, sink_relative_path)\n",
        "print('Primary storage account path: ' + sink_adls_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "mssparkutils.fs.unmount(\"/mnt/adlssink\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "mssparkutils.fs.mount( \n",
        "    # \"abfss://tiphackathon@synapsetiphackathon.dfs.core.windows.net/\",\n",
        "    f\"{sink_adls_path}\", \n",
        "    \"/mnt/adlssink\", \n",
        "    {\"linkedService\":f\"{sink_linked_service_name}\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "files = mssparkutils.fs.ls(\"/\")\n",
        "for file in files:\n",
        "    print(file.name, file.isDir, file.isFile, file.path, file.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "jobId = mssparkutils.env.getJobId()\r\n",
        "#print(jobId)\r\n",
        "sink_files = mssparkutils.fs.ls(f\"synfs:/{jobId}/mnt/adlssink/raw\")\r\n",
        "for file in sink_files:\r\n",
        "    print(file.name, file.isDir, file.isFile, file.path, file.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# mssparkutils.fs.cp -R f\"synfs:/{jobId}/mnt/blobsource/catalog_sales/\" f\"synfs:/{jobId}/mnt/adlssink/raw\"\r\n",
        "\r\n",
        "mssparkutils.fs.cp(f'synfs:/{jobId}/mnt/blobsource/catalog_sales/', f'synfs:/{jobId}/mnt/adlssink/raw', True)# Set the third parameter as True to copy all files and directories recursively\r\n",
        "mssparkutils.fs.cp(f'synfs:/{jobId}/mnt/blobsource/catalog_returns/', f'synfs:/{jobId}/mnt/adlssink/raw', True)# Set the third parameter as True to copy all files and directories recursively\r\n",
        "mssparkutils.fs.cp(f'synfs:/{jobId}/mnt/blobsource/catalog_page/', f'synfs:/{jobId}/mnt/adlssink/raw', True)# Set the third parameter as True to copy all files and directories recursively\r\n",
        "mssparkutils.fs.cp(f'synfs:/{jobId}/mnt/blobsource/warehouse/', f'synfs:/{jobId}/mnt/adlssink/raw', True)# Set the third parameter as True to copy all files and directories recursively"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}